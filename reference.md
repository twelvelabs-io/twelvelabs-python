# Reference
<details><summary><code>client.<a href="src/twelvelabs/base_client.py">summarize</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This endpoint analyzes videos and generates summaries, chapters, or highlights. Optionally, you can provide a prompt to customize the output.

<Note title="Note">
This endpoint is rate-limited. For details, see the [Rate limits](/v1.3/docs/get-started/rate-limits) page.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.summarize(
    video_id="6298d673f1090f1100476d4c",
    type="summary",
    prompt="Generate a summary of this video for a social media post, up to two sentences.",
    temperature=0.2,
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**video_id:** `str` ‚Äî The unique identifier of the video that you want to summarize.
    
</dd>
</dl>

<dl>
<dd>

**type:** `str` 

Specifies the type of summary. Use one of the following values:
  - `summary`: A brief that encapsulates the key points of a video, presenting the most important information clearly and concisely.
  - `chapter`: A chronological list of all the chapters in a video, providing a granular breakdown of its content. For each chapter, the platform returns its starting and end times, measured in seconds from the beginning of the video clip, a descriptive headline that offers a brief of the events or activities within that part of the video, and an accompanying summary that elaborates on the headline.
  - `highlight`: A chronologically ordered list of the most important events within a video. Unlike chapters, highlights only capture the key moments, providing a snapshot of the video's main topics. For each highlight, the platform returns its starting and end times, measured in seconds from the beginning of the video, a title, and a brief description that captures the essence of this part of the video.
    
</dd>
</dl>

<dl>
<dd>

**prompt:** `typing.Optional[str]` 

Use this field to provide context for the summarization task, such as the target audience, style, tone of voice, and purpose.

<Note title="Notes">
- Your prompts can be instructive or descriptive, or you can also phrase them as questions.
- The maximum length of a prompt is 2,000 tokens.
</Note>

**Example**: Generate a summary of this video for a social media post, up to two sentences.
    
</dd>
</dl>

<dl>
<dd>

**temperature:** `typing.Optional[float]` 

Controls the randomness of the text output generated by the model. A higher value generates more creative text, while a lower value produces more deterministic text output.

**Default:** 0.2
**Min:** 0
**Max:** 1
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.<a href="src/twelvelabs/base_client.py">gist</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This endpoint analyzes videos and generates titles, topics, and hashtags.

<Note title="Note">
This endpoint is rate-limited. For details, see the [Rate limits](/v1.3/docs/get-started/rate-limits) page.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.gist(
    video_id="6298d673f1090f1100476d4c",
    types=["title", "topic"],
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**video_id:** `str` ‚Äî The unique identifier of the video that you want to generate a gist for.
    
</dd>
</dl>

<dl>
<dd>

**types:** `typing.Sequence[GistRequestTypesItem]` 

Specifies the type of gist. Use one of the following values:
  - `title`: A title succinctly captures a video's main theme, such as "From Consumerism to Minimalism: A Journey Toward Sustainable Living," guiding viewers to its content and themes.
  - `topic`: A topic is the central theme of a video, such as "Shopping Vlog Lifestyle", summarizing its content for efficient categorization and reference.
  - `hashtag`: A hashtag, like "#BlackFriday", represents key themes in a video, enhancing its discoverability and categorization on social media platforms.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.<a href="src/twelvelabs/base_client.py">generate</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

<Warning>This endpoint will be deprecated on **July 30, 2025**. Transition to the [`/analyze`](/v1.3/api-reference/analyze-videos/analyze) endpoint, which provides identical functionality. Ensure you've updated your API calls before the deprecation date to ensure uninterrupted service.</Warning>

This endpoint generates open-ended texts based on your videos, including but not limited to tables of content, action items, memos, and detailed analyses.

<Note title="Notes">
- This endpoint is rate-limited. For details, see the [Rate limits](/v1.3/docs/get-started/rate-limits) page.
- This endpoint supports streaming responses. For details on integrating this feature into your application, refer to the [Streaming response](/v1.3/docs/guides/generate-text-from-video/open-ended-text#streaming-responses) guide.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.generate(
    video_id="6298d673f1090f1100476d4c",
    prompt="I want to generate a description for my video with the following format - Title of the video, followed by a summary in 2-3 sentences, highlighting the main topic, key events, and concluding remarks.",
    temperature=0.2,
    stream=True,
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**video_id:** `str` ‚Äî The unique identifier of the video for which you wish to generate a text.
    
</dd>
</dl>

<dl>
<dd>

**prompt:** `str` 

A prompt that guides the model on the desired format or content.

<Note title="Notes">
- Even though the model behind this endpoint is trained to a high degree of accuracy, the preciseness of the generated text may vary based on the nature and quality of the video and the clarity of the prompt.
- Your prompts can be instructive or descriptive, or you can also phrase them as questions.
- The maximum length of a prompt is 2,000 tokens.
</Note>

**Examples**:

- Based on this video, I want to generate five keywords for SEO (Search Engine Optimization).
- I want to generate a description for my video with the following format: Title of the video, followed by a summary in 2-3 sentences, highlighting the main topic, key events, and concluding remarks.
    
</dd>
</dl>

<dl>
<dd>

**temperature:** `typing.Optional[float]` 

Controls the randomness of the text output generated by the model. A higher value generates more creative text, while a lower value produces more deterministic text output.

**Default:** 0.2
**Min:** 0
**Max:** 1
    
</dd>
</dl>

<dl>
<dd>

**stream:** `typing.Optional[bool]` 

Set this parameter to `true` to enable streaming responses in the <a href="https://github.com/ndjson/ndjson-spec" target="_blank">NDJSON</a> format.

**Default:** `true`
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.<a href="src/twelvelabs/base_client.py">analyze_stream</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This endpoint analyzes your videos and creates fully customizable text based on your prompts, including but not limited to tables of content, action items, memos, and detailed analyses.

<Note title="Notes">
- This endpoint is rate-limited. For details, see the [Rate limits](/v1.3/docs/get-started/rate-limits) page.
- This endpoint supports streaming responses. For details on integrating this feature into your application, refer to the [Streaming response](/v1.3/docs/guides/generate-text-from-video/open-ended-text#streaming-responses) guide.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
response = client.analyze_stream(
    video_id="6298d673f1090f1100476d4c",
    prompt="I want to generate a description for my video with the following format - Title of the video, followed by a summary in 2-3 sentences, highlighting the main topic, key events, and concluding remarks.",
    temperature=0.2,
)
for chunk in response.data:
    yield chunk

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**video_id:** `str` ‚Äî The unique identifier of the video for which you wish to generate a text.
    
</dd>
</dl>

<dl>
<dd>

**prompt:** `str` 

A prompt that guides the model on the desired format or content.

<Note title="Notes">
- Even though the model behind this endpoint is trained to a high degree of accuracy, the preciseness of the generated text may vary based on the nature and quality of the video and the clarity of the prompt.
- Your prompts can be instructive or descriptive, or you can also phrase them as questions.
- The maximum length of a prompt is 2,000 tokens.
</Note>

**Examples**:

- Based on this video, I want to generate five keywords for SEO (Search Engine Optimization).
- I want to generate a description for my video with the following format: Title of the video, followed by a summary in 2-3 sentences, highlighting the main topic, key events, and concluding remarks.
    
</dd>
</dl>

<dl>
<dd>

**temperature:** `typing.Optional[float]` 

Controls the randomness of the text output generated by the model. A higher value generates more creative text, while a lower value produces more deterministic text output.

**Default:** 0.2
**Min:** 0
**Max:** 1
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.<a href="src/twelvelabs/base_client.py">analyze</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This endpoint analyzes your videos and creates fully customizable text based on your prompts, including but not limited to tables of content, action items, memos, and detailed analyses.

<Note title="Notes">
- This endpoint is rate-limited. For details, see the [Rate limits](/v1.3/docs/get-started/rate-limits) page.
- This endpoint supports streaming responses. For details on integrating this feature into your application, refer to the [Streaming response](/v1.3/docs/guides/generate-text-from-video/open-ended-text#streaming-responses) guide.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.analyze(
    video_id="6298d673f1090f1100476d4c",
    prompt="I want to generate a description for my video with the following format - Title of the video, followed by a summary in 2-3 sentences, highlighting the main topic, key events, and concluding remarks.",
    temperature=0.2,
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**video_id:** `str` ‚Äî The unique identifier of the video for which you wish to generate a text.
    
</dd>
</dl>

<dl>
<dd>

**prompt:** `str` 

A prompt that guides the model on the desired format or content.

<Note title="Notes">
- Even though the model behind this endpoint is trained to a high degree of accuracy, the preciseness of the generated text may vary based on the nature and quality of the video and the clarity of the prompt.
- Your prompts can be instructive or descriptive, or you can also phrase them as questions.
- The maximum length of a prompt is 2,000 tokens.
</Note>

**Examples**:

- Based on this video, I want to generate five keywords for SEO (Search Engine Optimization).
- I want to generate a description for my video with the following format: Title of the video, followed by a summary in 2-3 sentences, highlighting the main topic, key events, and concluding remarks.
    
</dd>
</dl>

<dl>
<dd>

**temperature:** `typing.Optional[float]` 

Controls the randomness of the text output generated by the model. A higher value generates more creative text, while a lower value produces more deterministic text output.

**Default:** 0.2
**Min:** 0
**Max:** 1
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Tasks
<details><summary><code>client.tasks.<a href="src/twelvelabs/tasks/client.py">list</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method returns a list of the video indexing tasks in your account. The API returns your video indexing tasks sorted by creation date, with the newest at the top of the list.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
response = client.tasks.list(
    page=1,
    page_limit=10,
    sort_by="created_at",
    sort_option="desc",
    index_id="630aff993fcee0532cb809d0",
    filename="01.mp4",
    duration=531.998133,
    width=640,
    height=360,
    created_at="2024-03-01T00:00:00Z",
    updated_at="2024-03-01T00:00:00Z",
)
for item in response:
    yield item
# alternatively, you can paginate page-by-page
for page in response.iter_pages():
    yield page

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**page:** `typing.Optional[int]` 

A number that identifies the page to retrieve.

**Default**: `1`.
    
</dd>
</dl>

<dl>
<dd>

**page_limit:** `typing.Optional[int]` 

The number of items to return on each page.

**Default**: `10`.
**Max**: `50`.
    
</dd>
</dl>

<dl>
<dd>

**sort_by:** `typing.Optional[str]` 

The field to sort on. The following options are available:
- `updated_at`: Sorts by the time, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"), when the item was updated.
- `created_at`: Sorts by the time, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"), when the item was created.

**Default**: `created_at`.
    
</dd>
</dl>

<dl>
<dd>

**sort_option:** `typing.Optional[str]` 

The sorting direction. The following options are available:
- `asc`
- `desc`

**Default**: `desc`.
    
</dd>
</dl>

<dl>
<dd>

**index_id:** `typing.Optional[str]` ‚Äî Filter by the unique identifier of an index.
    
</dd>
</dl>

<dl>
<dd>

**status:** `typing.Optional[
    typing.Union[
        TasksListRequestStatusItem, typing.Sequence[TasksListRequestStatusItem]
    ]
]` 

Filter by one or more video indexing task statuses. The following options are available:
- `ready`: The video has been successfully uploaded and indexed.
- `uploading`: The video is being uploaded.
- `validating`: The video is being validated against the prerequisites.
- `pending`: The video is pending.
- `queued`: The video is queued.
- `indexing`: The video is being indexed.
- `failed`: The video indexing task failed.

To filter by multiple statuses, specify the `status` parameter for each value:
```
status=ready&status=validating
```
    
</dd>
</dl>

<dl>
<dd>

**filename:** `typing.Optional[str]` ‚Äî Filter by filename.
    
</dd>
</dl>

<dl>
<dd>

**duration:** `typing.Optional[float]` ‚Äî Filter by duration. Expressed in seconds.
    
</dd>
</dl>

<dl>
<dd>

**width:** `typing.Optional[int]` ‚Äî Filter by width.
    
</dd>
</dl>

<dl>
<dd>

**height:** `typing.Optional[int]` ‚Äî Filter by height.
    
</dd>
</dl>

<dl>
<dd>

**created_at:** `typing.Optional[str]` ‚Äî Filter video indexing tasks by the creation date and time, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"). The platform returns the video indexing tasks that were created on the specified date at or after the given time.
    
</dd>
</dl>

<dl>
<dd>

**updated_at:** `typing.Optional[str]` ‚Äî Filter video indexing tasks by the last update date and time, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"). The platform returns the video indexing tasks that were updated on the specified date at or after the given time.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.tasks.<a href="src/twelvelabs/tasks/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method creates a video indexing task that uploads and indexes a video.

Upload options:
- **Local file**: Use the `video_file` parameter.
- **Publicly accessible URL**: Use the `video_url` parameter.

<Accordion title="Video requirements">
  The videos you wish to upload must meet the following requirements:
  - **Video resolution**: Must be at least 360x360 and must not exceed 3840x2160.
  - **Aspect ratio**: Must be one of 1:1, 4:3, 4:5, 5:4, 16:9, 9:16, or 17:9.
  - **Video and audio formats**: Your video files must be encoded in the video and audio formats listed on the [FFmpeg Formats Documentation](https://ffmpeg.org/ffmpeg-formats.html) page. For videos in other formats, contact us at support@twelvelabs.io.
  - **Duration**: For Marengo, it must be between 4 seconds and 2 hours (7,200s). For Pegasus, it must be between 4 seconds and 60 minutes (3600s). In a future release, the maximum duration for Pegasus will be 2 hours (7,200 seconds).
  - **File size**: Must not exceed 2 GB.
    If you require different options, contact us at support@twelvelabs.io.
  
  If both Marengo and Pegasus are enabled for your index, the most restrictive prerequisites will apply.
</Accordion>

<Note title="Notes">
- The platform supports video URLs that can play without additional user interaction or custom video players. Ensure your URL points to the raw video file, not a web page containing the video. Links to third-party hosting sites, cloud storage services, or videos requiring extra steps to play are not supported.
- This endpoint is rate-limited. For details, see the [Rate limits](/v1.3/docs/get-started/rate-limits) page.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.tasks.create(
    index_id="index_id",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**index_id:** `str` ‚Äî The unique identifier of the index to which the video is being uploaded.
    
</dd>
</dl>

<dl>
<dd>

**video_file:** `from __future__ import annotations

typing.Optional[core.File]` ‚Äî See core.File for more documentation
    
</dd>
</dl>

<dl>
<dd>

**video_url:** `typing.Optional[str]` ‚Äî Specify this parameter to upload a video from a publicly accessible URL.
    
</dd>
</dl>

<dl>
<dd>

**enable_video_stream:** `typing.Optional[bool]` ‚Äî This parameter indicates if the platform stores the video for streaming. When set to `true`, the platform stores the video, and you can retrieve its URL by calling the [`GET`](/v1.3/api-reference/videos/retrieve) method of the `/indexes/{index-id}/videos/{video-id}` endpoint. You can then use this URL to access the stream over the <a href="https://en.wikipedia.org/wiki/HTTP_Live_Streaming" target="_blank">HLS</a> protocol.
    
</dd>
</dl>

<dl>
<dd>

**user_metadata:** `typing.Optional[str]` ‚Äî Metadata that helps you categorize your videos. You can specify a list of keys and values. Keys must be of type `string`, and values can be of the following types: `string`, `integer`, `float` or `boolean`.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.tasks.<a href="src/twelvelabs/tasks/client.py">retrieve</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method retrieves a video indexing task.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.tasks.retrieve(
    task_id="6298d673f1090f1100476d4c",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**task_id:** `str` ‚Äî The unique identifier of the video indexing task to retrieve.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.tasks.<a href="src/twelvelabs/tasks/client.py">delete</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This action cannot be undone.
Note the following about deleting a video indexing task:
- You can only delete video indexing tasks for which the status is `ready` or `failed`.
- If the status of your video indexing task is `ready`, you must first delete the video vector associated with your video indexing task by calling the [`DELETE`](/v1.3/api-reference/videos/delete) method of the `/indexes/videos` endpoint.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.tasks.delete(
    task_id="6298d673f1090f1100476d4c",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**task_id:** `str` ‚Äî The unique identifier of the video indexing task you want to delete.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Indexes
<details><summary><code>client.indexes.<a href="src/twelvelabs/indexes/client.py">list</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method returns a list of the indexes in your account. The API returns indexes sorted by creation date, with the oldest indexes at the top of the list.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
response = client.indexes.list(
    page=1,
    page_limit=10,
    sort_by="created_at",
    sort_option="desc",
    index_name="myIndex",
    model_options="visual,audio",
    model_family="marengo",
    created_at="2024-08-16T16:53:59Z",
    updated_at="2024-08-16T16:55:59Z",
)
for item in response:
    yield item
# alternatively, you can paginate page-by-page
for page in response.iter_pages():
    yield page

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**page:** `typing.Optional[int]` 

A number that identifies the page to retrieve.

**Default**: `1`.
    
</dd>
</dl>

<dl>
<dd>

**page_limit:** `typing.Optional[int]` 

The number of items to return on each page.

**Default**: `10`.
**Max**: `50`.
    
</dd>
</dl>

<dl>
<dd>

**sort_by:** `typing.Optional[str]` 

The field to sort on. The following options are available:
- `updated_at`: Sorts by the time, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"), when the item was updated.
- `created_at`: Sorts by the time, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"), when the item was created.

**Default**: `created_at`.
    
</dd>
</dl>

<dl>
<dd>

**sort_option:** `typing.Optional[str]` 

The sorting direction. The following options are available:
- `asc`
- `desc`

**Default**: `desc`.
    
</dd>
</dl>

<dl>
<dd>

**index_name:** `typing.Optional[str]` ‚Äî Filter by the name of an index.
    
</dd>
</dl>

<dl>
<dd>

**model_options:** `typing.Optional[str]` ‚Äî Filter by the model options. When filtering by multiple model options, the values must be comma-separated.
    
</dd>
</dl>

<dl>
<dd>

**model_family:** `typing.Optional[str]` ‚Äî Filter by the model family. This parameter can take one of the following values: `marengo` or `pegasus`. You can specify a single value.
    
</dd>
</dl>

<dl>
<dd>

**created_at:** `typing.Optional[str]` ‚Äî Filter indexes by the creation date and time, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"). The platform returns the indexes that were created on the specified date at or after the given time.
    
</dd>
</dl>

<dl>
<dd>

**updated_at:** `typing.Optional[str]` ‚Äî Filter indexes by the last update date and time, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"). The platform returns the indexes that were last updated on the specified date at or after the given time.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.indexes.<a href="src/twelvelabs/indexes/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method creates an index.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs
from twelvelabs.indexes import IndexesCreateRequestModelsItem

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.indexes.create(
    index_name="myIndex",
    models=[
        IndexesCreateRequestModelsItem(
            model_name="marengo2.7",
            model_options=["visual", "audio"],
        ),
        IndexesCreateRequestModelsItem(
            model_name="pegasus1.2",
            model_options=["visual", "audio"],
        ),
    ],
    addons=["thumbnail"],
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**index_name:** `str` ‚Äî The name of the index. Make sure you use a succinct and descriptive name.
    
</dd>
</dl>

<dl>
<dd>

**models:** `typing.Sequence[IndexesCreateRequestModelsItem]` ‚Äî An array that specifies the [video understanding models](/v1.3/docs/concepts/models) and the [model options](/v1.3/docs/concepts/modalities#model-options) to be enabled for this index. This determines how the platform processes your videos.
    
</dd>
</dl>

<dl>
<dd>

**addons:** `typing.Optional[typing.Sequence[str]]` 

An array specifying which add-ons should be enabled. Each entry in the array is an addon, and the following values are supported:
- `thumbnail`: Enables thumbnail generation.

If you don't provide this parameter, no add-ons will be enabled.

<Note title="Notes">
- You can only enable addons when using the Marengo video understanding model.
- You cannot disable an add-on once the index has been created.
</Note>
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.indexes.<a href="src/twelvelabs/indexes/client.py">retrieve</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method retrieves details about the specified index.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.indexes.retrieve(
    index_id="6298d673f1090f1100476d4c",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**index_id:** `str` ‚Äî Unique identifier of the index to retrieve.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.indexes.<a href="src/twelvelabs/indexes/client.py">update</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method updates the name of the specified index.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.indexes.update(
    index_id="6298d673f1090f1100476d4c",
    index_name="myIndex",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**index_id:** `str` ‚Äî Unique identifier of the index to update.
    
</dd>
</dl>

<dl>
<dd>

**index_name:** `str` ‚Äî The name of the index.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.indexes.<a href="src/twelvelabs/indexes/client.py">delete</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method deletes the specified index and all the videos within it. This action cannot be undone.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.indexes.delete(
    index_id="6298d673f1090f1100476d4c",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**index_id:** `str` ‚Äî Unique identifier of the index to delete.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Manage videos
<details><summary><code>client.manage_videos.<a href="src/twelvelabs/manage_videos/client.py">partial_update_video_information</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

Use this method to update one or more fields of the metadata of a video. Also, you can delete a field by setting it to `null`.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.manage_videos.partial_update_video_information(
    index_id="6298d673f1090f1100476d4c",
    video_id="6298d673f1090f1100476d4c",
    user_metadata={
        "category": "recentlyAdded",
        "batchNumber": 5,
        "rating": 9.3,
        "needsReview": True,
    },
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**index_id:** `str` ‚Äî The unique identifier of the index to which the video has been uploaded.
    
</dd>
</dl>

<dl>
<dd>

**video_id:** `str` ‚Äî The unique identifier of the video to update.
    
</dd>
</dl>

<dl>
<dd>

**user_metadata:** `typing.Optional[UserMetadata]` 
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Embed
<details><summary><code>client.embed.<a href="src/twelvelabs/embed/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method creates embeddings for text, image, and audio content.

Before you create an embedding, ensure that your image or audio files meet the following prerequisites:
- [Image embeddings](/v1.3/docs/guides/create-embeddings/image#prerequisites)
- [Audio embeddings](/v1.3/docs/guides/create-embeddings/audio#prerequisites)

Parameters for embeddings:
- **Common parameters**:
  - `model_name`: The video understanding model you want to use. Example: "Marengo-retrieval-2.7".
- **Text embeddings**:
  - `text`: Text for which to create an embedding.
- **Image embeddings**:
  Provide one of the following:
  - `image_url`: Publicly accessible URL of your image file.
  - `image_file`:  Local image file.
- **Audio embeddings**:
  Provide one of the following:
  - `audio_url`: Publicly accessible URL of your audio file.
  - `audio_file`: Local audio file.

<Note title="Notes">
- The "Marengo-retrieval-2.7" video understanding model generates embeddings for all modalities in the same latent space. This shared space enables any-to-any searches across different types of content.
- You can create multiple types of embeddings in a single API call.
- Audio embeddings combine generic sound and human speech in a single embedding. For videos with transcriptions, you can retrieve transcriptions and then [create text embeddings](/v1.3/api-reference/text-image-audio-embeddings/create-text-image-audio-embeddings) from these transcriptions.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.embed.create(
    model_name="model_name",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**model_name:** `str` 

The name of the model you want to use. The following models are available:
  - `Marengo-retrieval-2.7`
    
</dd>
</dl>

<dl>
<dd>

**text:** `typing.Optional[str]` 

The text for which you wish to create an embedding.

<Note title="Note">
Text embeddings are limited to 77 tokens. If the text exceeds this limit, the platform truncates it according to the value of the `text_truncate` parameter described below.
</Note>

**Example**: "Man with a dog crossing the street"
    
</dd>
</dl>

<dl>
<dd>

**text_truncate:** `typing.Optional[str]` 

Specifies how the platform truncates text that exceeds 77 tokens to fit the maximum length allowed for an embedding.
This parameter can take one of the following values:
- `start`: The platform will truncate the start of the provided text.
- `end`: The platform will truncate the end of the provided text.
- `none`: The platform will return an error if the text is longer than the maximum token limit.

**Default**: `end`
    
</dd>
</dl>

<dl>
<dd>

**image_url:** `typing.Optional[str]` ‚Äî The publicly accessible URL of the image for which you wish to create an embedding. This parameter is required for image embeddings if `image_file` is not provided.
    
</dd>
</dl>

<dl>
<dd>

**image_file:** `from __future__ import annotations

typing.Optional[core.File]` ‚Äî See core.File for more documentation
    
</dd>
</dl>

<dl>
<dd>

**audio_url:** `typing.Optional[str]` ‚Äî The publicly accessible URL of the audio file for which you wish to creae an embedding. This parameter is required for audio embeddings if `audio_file` is not provided.
    
</dd>
</dl>

<dl>
<dd>

**audio_file:** `from __future__ import annotations

typing.Optional[core.File]` ‚Äî See core.File for more documentation
    
</dd>
</dl>

<dl>
<dd>

**audio_start_offset_sec:** `typing.Optional[float]` 

Specifies the start time, in seconds, from which the platform generates the audio embeddings. This parameter allows you to skip the initial portion of the audio during processing.
**Default**: `0`.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Search
<details><summary><code>client.search.<a href="src/twelvelabs/search/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

Use this endpoint to search for relevant matches in an index using text or various media queries.

**Text queries**:
- Use the `query_text` parameter to specify your query.

**Media queries**:
- Set the `query_media_type` parameter to the corresponding media type (example: `image`).
- Specify either one of the following parameters:
  - `query_media_url`: Publicly accessible URL of your media file.
  - `query_media_file`: Local media file.
  If both `query_media_url` and `query_media_file` are specified in the same request, `query_media_url` takes precedence.
<Accordion title="Image requirements">
Your images must meet the following requirements:
  - **Format**: JPEG and PNG.
  - **Dimension**: Must be at least 64 x 64 pixels.
  - **Size**: Must not exceed 5MB.
</Accordion>

<Note title="Note">
This endpoint is rate-limited. For details, see the [Rate limits](/v1.3/docs/get-started/rate-limits) page.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.search.create(
    index_id="index_id",
    search_options=["visual"],
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**index_id:** `str` ‚Äî The unique identifier of the index to search.
    
</dd>
</dl>

<dl>
<dd>

**search_options:** `typing.List[SearchCreateRequestSearchOptionsItem]` 

Specifies the [sources of information](/v1.3/docs/concepts/modalities#search-options) the platform uses when performing a search. You must include the `search_options` parameter separately for each desired source of information.

<Note title="Notes">
- The search options you specify must be a subset of the [model options](/v1.3/docs/concepts/modalities#model-options) used when you created the index.
- You can specify multiple search options in conjunction with the `operator` parameter described below to broaden or narrow your search.

Example:
To search using both visual and audio cues, include this parameter twice in the request as shown below:
```JSON
--form search_options=visual \
--form search_options=audio \
```
</Note>
    
</dd>
</dl>

<dl>
<dd>

**query_media_type:** `typing.Optional[typing.Literal["image"]]` ‚Äî The type of media you wish to use. This parameter is required for media queries. For example, to perform an image-based search, set this parameter to `image`.
    
</dd>
</dl>

<dl>
<dd>

**query_media_url:** `typing.Optional[str]` ‚Äî The publicly accessible URL of the media file you wish to use. This parameter is required for media queries if `query_media_file` is not provided.
    
</dd>
</dl>

<dl>
<dd>

**query_media_file:** `from __future__ import annotations

typing.Optional[core.File]` ‚Äî See core.File for more documentation
    
</dd>
</dl>

<dl>
<dd>

**query_text:** `typing.Optional[str]` ‚Äî The text query to search for. This parameter is required for text queries. Note that the platform supports full natural language-based search.
    
</dd>
</dl>

<dl>
<dd>

**adjust_confidence_level:** `typing.Optional[float]` 

This parameter specifies the strictness of the thresholds for assigning the high, medium, or low confidence levels to search results. If you use a lower value, the thresholds become more relaxed, and more search results will be classified as having high, medium, or low confidence levels. You can use this parameter to include a broader range of potentially relevant video clips, even if some results might be less precise.

**Min**: 0
**Max**: 1
**Default:** 0.5
    
</dd>
</dl>

<dl>
<dd>

**group_by:** `typing.Optional[SearchCreateRequestGroupBy]` 

Use this parameter to group or ungroup items in a response. It can take one of the following values:
- `video`:  The platform will group the matching video clips in the response by video.
- `clip`: The matching video clips in the response will not be grouped.

**Default:** `clip`
    
</dd>
</dl>

<dl>
<dd>

**threshold:** `typing.Optional[ThresholdSearch]` 
    
</dd>
</dl>

<dl>
<dd>

**sort_option:** `typing.Optional[SearchCreateRequestSortOption]` 

Use this parameter to specify the sort order for the response.

When performing a search, the platform determines the level of confidence that each video clip matches your search terms. By default, the search results are sorted on the level of confidence in descending order.

If you set this parameter to `score` and `group_by` is set to `video`, the platform will determine the maximum value of the `score` field for each video and sort the videos in the response by the maximum value of this field. For each video, the matching video clips will be sorted by the level of confidence.

If you set this parameter to `clip_count` and `group_by` is set to `video`, the platform will sort the videos in the response by the number of clips. For each video, the matching video clips will be sorted by the level of confidence. You can use `clip_count` only when the matching video clips are grouped by video.


**Default:** `score`
    
</dd>
</dl>

<dl>
<dd>

**operator:** `typing.Optional[SearchCreateRequestOperator]` 

When you perform a search specifying multiple [sources of information](/v1.3/docs/concepts/modalities#search-options), you can use the this parameter to broaden or narrow your search.

  The following logical operators are supported:

  - `or`

  - `and`

  For details and examples, see the [Using multiple sources of information](/v1.3/docs/guides/search/queries/text-queries#visual-and-audio) section.


  **Default**: `or`.
    
</dd>
</dl>

<dl>
<dd>

**page_limit:** `typing.Optional[int]` 

The number of items to return on each page. When grouping by video, this parameter represents the number of videos per page. Otherwise, it represents the maximum number of video clips per page.

**Max**: `50`.
    
</dd>
</dl>

<dl>
<dd>

**filter:** `typing.Optional[str]` 

Specifies a stringified JSON object to filter your search results. Supports both system-generated metadata (example: video ID, duration) and user-defined metadata.

**Syntax for filtering**

The following table describes the supported data types, operators, and filter syntax: 

| Data type | Operator | Description | Syntax |
|:----------|:---------|:------------|:-------|
| String | `=` | Matches results equal to the specified value. | `{"field": "value"}` 
| Array of strings | `=` | Matches results with any value in the specified array. Supported only for `id`. | `{"id": ["value1", "value2"]}` |
| Numeric (integer, float) | `=`, `lte`, `gte` | Matches results equal to or within a range of the specified value. | `{"field": number}` or `{"field": { "gte": number, "lte": number }}` |
| Boolean | `=` | Matches results equal to the specified boolean value. | `{"field": true}` or `{"field": false}`. |

<br/>
**System-generated metadata**

The table below describes the system-generated metadata available for filtering your  search results:

| Field name | Description | Type | Example |
|:-----------|:------------|:-----|:--------|
| `id` | Filters by specific video IDs. | Array of strings | `{"id": ["67cec9caf45d9b64a58340fc", "67cec9baf45d9b64a58340fa"]}`. |
| `duration` | Filters based on the duration of the video containing the segment that matches your query. | Number or object with `gte` and `lte` | `{"duration": 600}` or `{"duration": { "gte": 600, "lte": 800 }}` |
| `width` | Filters by video width (in pixels). | Number or object with `gte` and `lte` | `{"width": 1920}` or `{"width": { "gte": 1280, "lte": 1920}}` |
| `height` | Filters by video height (in pixels). | Number or object with `gte` and `lte`. | `{"height": 1080}` or `{"height": { "gte": 720, "lte": 1080 }}`. |
| `size` | Filters by video size (in bytes) | Number or object with `gte` and `lte`. | `{"size": 1048576}` or `{"size": { "gte": 1048576, "lte": 5242880}}` | 
| `filename` | Filters by the exact file name. | String | `{"filename": "Animal Encounters part 1"}` | 

<br/>
**User-defined metadata**

To filter by user-defined metadata:
1. Add metadata to your video by calling the [`PUT`](/v1.3/api-reference/videos/update) method of the `/indexes/:index-id/videos/:video-id` endpoint
2. Reference the custom field in your filter object. For example, to filter videos where a custom field named `needsReview` of type boolean is `true`, use `{"needs_review": true}`.

For more details and examples, see the [Filter search results](/v1.3/docs/guides/search/filtering) page.
    
</dd>
</dl>

<dl>
<dd>

**include_user_metadata:** `typing.Optional[bool]` ‚Äî Specifies whether to include user-defined metadata in the search results.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.search.<a href="src/twelvelabs/search/client.py">retrieve</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

Use this endpoint to retrieve a specific page of search results.

<Note title="Note">
When you use pagination, you will not be charged for retrieving subsequent pages of results.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.search.retrieve(
    page_token="1234567890",
    include_user_metadata=True,
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**page_token:** `str` ‚Äî A token that identifies the page to retrieve.
    
</dd>
</dl>

<dl>
<dd>

**include_user_metadata:** `typing.Optional[bool]` ‚Äî Specifies whether to include user-defined metadata in the search results.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Embed Tasks
<details><summary><code>client.embed.tasks.<a href="src/twelvelabs/embed/tasks/client.py">list</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method returns a list of the video embedding tasks in your account. The platform returns your video embedding tasks sorted by creation date, with the newest at the top of the list.

<Note title="Notes">
- Video embeddings are stored for seven days
- When you invoke this method without specifying the `started_at` and `ended_at` parameters, the platform returns all the video embedding tasks created within the last seven days.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
response = client.embed.tasks.list(
    started_at="2024-03-01T00:00:00Z",
    ended_at="2024-03-01T00:00:00Z",
    status="processing",
    page=1,
    page_limit=10,
)
for item in response:
    yield item
# alternatively, you can paginate page-by-page
for page in response.iter_pages():
    yield page

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**started_at:** `typing.Optional[str]` ‚Äî Retrieve the video embedding tasks that were created after the given date and time, expressed in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ").
    
</dd>
</dl>

<dl>
<dd>

**ended_at:** `typing.Optional[str]` ‚Äî Retrieve the video embedding tasks that were created before the given date and time, expressed in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ").
    
</dd>
</dl>

<dl>
<dd>

**status:** `typing.Optional[str]` ‚Äî Filter video embedding tasks by their current status. Possible values are `processing`, `ready`, or `failed`.
    
</dd>
</dl>

<dl>
<dd>

**page:** `typing.Optional[int]` 

A number that identifies the page to retrieve.

**Default**: `1`.
    
</dd>
</dl>

<dl>
<dd>

**page_limit:** `typing.Optional[int]` 

The number of items to return on each page.

**Default**: `10`.
**Max**: `50`.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.embed.tasks.<a href="src/twelvelabs/embed/tasks/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method creates a new video embedding task that uploads a video to the platform and creates one or multiple video embeddings.

Upload options:
- **Local file**: Use the `video_file` parameter
- **Publicly accessible URL**: Use the `video_url` parameter.

Specify at least one option. If both are provided, `video_url` takes precedence.

<Accordion title="Video requirements">
  The videos you wish to upload must meet the following requirements:
  - **Video resolution**: Must be at least 360x360 and must not exceed 3840x2160.
  - **Aspect ratio**: Must be one of 1:1, 4:3, 4:5, 5:4, 16:9, 9:16, or 17:9.
  - **Video and audio formats**: Your video files must be encoded in the video and audio formats listed on the [FFmpeg Formats Documentation](https://ffmpeg.org/ffmpeg-formats.html) page. For videos in other formats, contact us at support@twelvelabs.io.
  - **Duration**: Must be between 4 seconds and 2 hours (7,200s).
  - **File size**: Must not exceed 2 GB.
    If you require different options, contact us at support@twelvelabs.io.
</Accordion>

<Note title="Notes">
- The "Marengo-retrieval-2.7" video understanding model generates embeddings for all modalities in the same latent space. This shared space enables any-to-any searches across different types of content.
- Video embeddings are stored for seven days.
- The platform supports uploading video files that can play without additional user interaction or custom video players. Ensure your URL points to the raw video file, not a web page containing the video. Links to third-party hosting sites, cloud storage services, or videos requiring extra steps to play are not supported.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.embed.tasks.create(
    model_name="model_name",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**model_name:** `str` 

The name of the model you want to use. The following models are available:
  - `Marengo-retrieval-2.7`
    
</dd>
</dl>

<dl>
<dd>

**video_file:** `from __future__ import annotations

typing.Optional[core.File]` ‚Äî See core.File for more documentation
    
</dd>
</dl>

<dl>
<dd>

**video_url:** `typing.Optional[str]` ‚Äî Specify this parameter to upload a video from a publicly accessible URL.
    
</dd>
</dl>

<dl>
<dd>

**video_start_offset_sec:** `typing.Optional[float]` 

The start offset in seconds from the beginning of the video where processing should begin. Specifying 0 means starting from the beginning of the video.

**Default**: 0
**Min**: 0
**Max**: Duration of the video minus video_clip_length
    
</dd>
</dl>

<dl>
<dd>

**video_end_offset_sec:** `typing.Optional[float]` 

The end offset in seconds from the beginning of the video where processing should stop.

Ensure the following when you specify this parameter:
- The end offset does not exceed the total duration of the video file.
- The end offset is greater than the start offset.
- You must set both the start and end offsets. Setting only one of these offsets is not permitted, resulting in an error.

**Min**: video_start_offset + video_clip_length
**Max**: Duration of the video file
    
</dd>
</dl>

<dl>
<dd>

**video_clip_length:** `typing.Optional[float]` 

The desired duration in seconds for each clip for which the platform generates an embedding. Ensure that the clip length does not exceed the interval between the start and end offsets.

**Default**: 6
**Min**: 2
**Max**: 10
    
</dd>
</dl>

<dl>
<dd>

**video_embedding_scope:** `typing.Optional[typing.List[TasksCreateRequestVideoEmbeddingScopeItem]]` 

Defines the scope of video embedding generation. Valid values are the following:
- `clip`: Creates embeddings for each video segment of `video_clip_length` seconds, from `video_start_offset_sec` to `video_end_offset_sec`.
- `clip` and `video`: Creates embeddings for video segments and the entire video.

To create embeddings for segments and the entire video in the same request, include this parameter twice as shown below:

```json
--form video_embedding_scope=clip \
--form video_embedding_scope=video
```

**Default**: `clip`
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.embed.tasks.<a href="src/twelvelabs/embed/tasks/client.py">status</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method retrieves the status of a video embedding task. Check the task status of a video embedding task to determine when you can retrieve the embedding.

A task can have one of the following statuses:
- `processing`: The platform is creating the embeddings.
- `ready`:  Processing is complete. Retrieve the embeddings by invoking the [`GET`](/v1.3/api-reference/video-embeddings/retrieve-video-embeddings) method of the `/embed/tasks/{task_id} endpoint`.
- `failed`: The task could not be completed, and the embeddings haven't been created.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.embed.tasks.status(
    task_id="663da73b31cdd0c1f638a8e6",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**task_id:** `str` ‚Äî The unique identifier of your video embedding task.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.embed.tasks.<a href="src/twelvelabs/embed/tasks/client.py">retrieve</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method retrieves embeddings for a specific video embedding task. Ensure the task status is `ready` before invoking this method. Refer to the [Retrieve the status of a video embedding tasks](/v1.3/api-reference/video-embeddings/retrieve-video-embedding-task-status) page for instructions on checking the task status.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.embed.tasks.retrieve(
    task_id="663da73b31cdd0c1f638a8e6",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**task_id:** `str` ‚Äî The unique identifier of your video embedding task.
    
</dd>
</dl>

<dl>
<dd>

**embedding_option:** `typing.Optional[
    typing.Union[
        TasksRetrieveRequestEmbeddingOptionItem,
        typing.Sequence[TasksRetrieveRequestEmbeddingOptionItem],
    ]
]` 

Specifies which types of embeddings to retrieve. You can include one or more of the following values:
  - `visual-text`:  Returns visual embeddings optimized for text search.
  - `audio`: Returns audio embeddings.

The platform returns all available embeddings if you don't provide this parameter.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Indexes Videos
<details><summary><code>client.indexes.videos.<a href="src/twelvelabs/indexes/videos/client.py">list</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method returns a list of the videos in the specified index. By default, the API returns your videos sorted by creation date, with the newest at the top of the list.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
response = client.indexes.videos.list(
    index_id="6298d673f1090f1100476d4c",
    page=1,
    page_limit=10,
    sort_by="created_at",
    sort_option="desc",
    filename="01.mp4",
    created_at="2024-08-16T16:53:59Z",
    updated_at="2024-08-16T16:53:59Z",
)
for item in response:
    yield item
# alternatively, you can paginate page-by-page
for page in response.iter_pages():
    yield page

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**index_id:** `str` ‚Äî The unique identifier of the index for which the API will retrieve the videos.
    
</dd>
</dl>

<dl>
<dd>

**page:** `typing.Optional[int]` 

A number that identifies the page to retrieve.

**Default**: `1`.
    
</dd>
</dl>

<dl>
<dd>

**page_limit:** `typing.Optional[int]` 

The number of items to return on each page.

**Default**: `10`.
**Max**: `50`.
    
</dd>
</dl>

<dl>
<dd>

**sort_by:** `typing.Optional[str]` 

The field to sort on. The following options are available:
- `updated_at`: Sorts by the time, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"), when the item was updated.
- `created_at`: Sorts by the time, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"), when the item was created.

**Default**: `created_at`.
    
</dd>
</dl>

<dl>
<dd>

**sort_option:** `typing.Optional[str]` 

The sorting direction. The following options are available:
- `asc`
- `desc`

**Default**: `desc`.
    
</dd>
</dl>

<dl>
<dd>

**filename:** `typing.Optional[str]` ‚Äî Filter by filename.
    
</dd>
</dl>

<dl>
<dd>

**duration:** `typing.Optional[float]` ‚Äî Filter by duration. Expressed in seconds.
    
</dd>
</dl>

<dl>
<dd>

**fps:** `typing.Optional[float]` ‚Äî Filter by frames per second.
    
</dd>
</dl>

<dl>
<dd>

**width:** `typing.Optional[float]` ‚Äî Filter by width.
    
</dd>
</dl>

<dl>
<dd>

**height:** `typing.Optional[int]` ‚Äî Filter by height.
    
</dd>
</dl>

<dl>
<dd>

**size:** `typing.Optional[float]` ‚Äî Filter by size. Expressed in bytes.
    
</dd>
</dl>

<dl>
<dd>

**created_at:** `typing.Optional[str]` ‚Äî Filter videos by the creation date and time of their associated indexing tasks, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"). The platform returns the videos whose indexing tasks were created on the specified date at or after the given time.
    
</dd>
</dl>

<dl>
<dd>

**updated_at:** `typing.Optional[str]` ‚Äî This filter applies only to videos updated using the [`PUT`](/v1.3/api-reference/videos/update) method of the `/indexes/{index-id}/videos/{video-id}` endpoint. It filters videos by the last update date and time, in the RFC 3339 format ("YYYY-MM-DDTHH:mm:ssZ"). The platform returns the video indexing tasks that were last updated on the specified date at or after the given time.
    
</dd>
</dl>

<dl>
<dd>

**user_metadata:** `typing.Optional[
    typing.Dict[str, typing.Optional[VideosListRequestUserMetadataValue]]
]` 

To enable filtering by custom fields, you must first add user-defined metadata to your video by calling the [`PUT`](/v1.3/api-reference/videos/update) method of the `/indexes/:index-id/videos/:video-id` endpoint.

Examples:
- To filter on a string: `?category=recentlyAdded`
- To filter on an integer: `?batchNumber=5`
- To filter on a float: `?rating=9.3`
- To filter on a boolean: `?needsReview=true`
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.indexes.videos.<a href="src/twelvelabs/indexes/videos/client.py">retrieve</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method retrieves information about the specified video.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.indexes.videos.retrieve(
    index_id="6298d673f1090f1100476d4c",
    video_id="6298d673f1090f1100476d4c",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**index_id:** `str` ‚Äî The unique identifier of the index to which the video has been uploaded.
    
</dd>
</dl>

<dl>
<dd>

**video_id:** `str` ‚Äî The unique identifier of the video to retrieve.
    
</dd>
</dl>

<dl>
<dd>

**embedding_option:** `typing.Optional[
    typing.Union[
        VideosRetrieveRequestEmbeddingOptionItem,
        typing.Sequence[VideosRetrieveRequestEmbeddingOptionItem],
    ]
]` 

Specifies which types of embeddings to retrieve. You can include one or more of the following values:
- `visual-text`:  Returns visual embeddings optimized for text search.
- `audio`: Returns audio embeddings.
<br/>
To retrieve embeddings for a video, it must be indexed using the Marengo video understanding model version 2.7 or later. For details on enabling this model for an index, see the [Create an index](/reference/create-index) page.

The platform does not return embeddings if you don't provide this parameter.

The values you specify in `embedding_option` must be included in the `model_options` defined when the index was created. For example, if `model_options` is set to `visual,` you cannot set `embedding_option` to `audio` or  both `visual-text` and `audio`.
    
</dd>
</dl>

<dl>
<dd>

**transcription:** `typing.Optional[bool]` ‚Äî The parameter indicates whether to retrieve a transcription of the spoken words for the indexed video. Note that the official SDKs will support this feature in a future release.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.indexes.videos.<a href="src/twelvelabs/indexes/videos/client.py">update</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

Use this method to update the metadata of a video.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.indexes.videos.update(
    index_id="6298d673f1090f1100476d4c",
    video_id="6298d673f1090f1100476d4c",
    user_metadata={
        "category": "recentlyAdded",
        "batchNumber": 5,
        "rating": 9.3,
        "needsReview": True,
    },
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**index_id:** `str` ‚Äî The unique identifier of the index to which the video has been uploaded.
    
</dd>
</dl>

<dl>
<dd>

**video_id:** `str` ‚Äî The unique identifier of the video to update.
    
</dd>
</dl>

<dl>
<dd>

**user_metadata:** `typing.Optional[UserMetadata]` 
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.indexes.videos.<a href="src/twelvelabs/indexes/videos/client.py">delete</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method deletes all the information about the specified video. This action cannot be undone.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.indexes.videos.delete(
    index_id="6298d673f1090f1100476d4c",
    video_id="6298d673f1090f1100476d4c",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**index_id:** `str` ‚Äî The unique identifier of the index to which the video has been uploaded.
    
</dd>
</dl>

<dl>
<dd>

**video_id:** `str` ‚Äî The unique identifier of the video to delete.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Tasks Transfers
<details><summary><code>client.tasks.transfers.<a href="src/twelvelabs/tasks/transfers/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

An import represents the process of uploading and indexing all videos from the specified integration.

This method initiates an asynchronous import and returns two lists:
- Videos that will be imported.
- Videos that will not be imported, typically because they do not meet the prerequisites of all enabled video understanding models for your index. Note that the most restrictive prerequisites among the enabled models will apply.

The actual uploading and indexing of videos occur asynchronously after you invoke this method. To monitor the status of each upload after invoking this method, use the [Retrieve import status](/v1.3/api-reference/tasks/cloud-to-cloud-integrations/get-status) method.

<Accordion title="Video requirements">
  The videos you wish to upload must meet the following requirements:
  - **Video resolution**: Must be at least 360x360 and must not exceed 3840x2160.
  - **Aspect ratio**: Must be one of 1:1, 4:3, 4:5, 5:4, 16:9, 9:16, or 17:9.
  - **Video and audio formats**: Your video files must be encoded in the video and audio formats listed on the [FFmpeg Formats Documentation](https://ffmpeg.org/ffmpeg-formats.html) page. For videos in other formats, contact us at support@twelvelabs.io.
  - **Duration**: For Marengo, it must be between 4 seconds and 2 hours (7,200s). For Pegasus, it must be between 4 seconds and 60 minutes (3600s). In a future release, the maximum duration for Pegasus will be 2 hours (7,200 seconds).
  - **File size**: Must not exceed 2 GB.
    If you require different options, contact us at support@twelvelabs.io.

  If both Marengo and Pegasus are enabled for your index, the most restrictive prerequisites will apply.
</Accordion>

<Note title="Notes">
- Before importing videos, you must set up an integration. For details, see the [Set up an integration](/v1.3/docs/advanced/cloud-to-cloud-integrations#set-up-an-integration) section.
- By default, the platform checks for duplicate files using hashes within the target index and will not upload the same video to the same index twice. However, the same video can exist in multiple indexes. To bypass duplicate checking entirely and import duplicate videos into the same index, set the value of the `incremental_import` parameter to `false`.
- Only one import job can run at a time. To start a new import, wait for the current job to complete. Use the [`GET`](/v1.3/api-reference/tasks/cloud-to-cloud-integrations/get-status) method of the `/tasks/transfers/import/{integration-id}/logs` endpoint to retrieve a list of your import jobs, including their creation time, completion time, and processing status for each video file.
</Note>
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.tasks.transfers.create(
    integration_id="6298d673f1090f1100476d4c",
    index_id="6298d673f1090f1100476d4c",
    incremental_import=True,
    retry_failed=False,
    user_metadata={"category": "recentlyAdded", "batchNumber": 5},
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**integration_id:** `str` ‚Äî The unique identifier of the integration for which you want to import videos. You can retrieve it from the [Integrations](https://playground.twelvelabs.io/dashboard/integrations) page.
    
</dd>
</dl>

<dl>
<dd>

**index_id:** `str` ‚Äî The unique identifier of the index to which the videos are being uploaded.
    
</dd>
</dl>

<dl>
<dd>

**incremental_import:** `typing.Optional[bool]` 

Specifies whether or not incremental sync is enabled. If set to `false`, the platform will synchronize all the files in the bucket.

**Default**: `true`.
    
</dd>
</dl>

<dl>
<dd>

**retry_failed:** `typing.Optional[bool]` 

Determines whether the platform retries failed uploads. When set to `true`, the platform attempts to re-upload files that failed during the initial upload process.

**Default**: `false`.
    
</dd>
</dl>

<dl>
<dd>

**user_metadata:** `typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]` 

Metadata that helps you categorize your videos. You can specify a list of keys and values. Keys must be of type `string`, and values can be of the following types: `string`, `integer`, `float` or `boolean`.

<Note title="Notes">
- The metadata you specify when calling this method applies to all videos imported in this request.
-  If you want to store other types of data such as objects or arrays, you must convert your data into string values.
- You cannot override any of the predefined metadata (example: duration, width, length, etc) associated with a video.
</Note>
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.tasks.transfers.<a href="src/twelvelabs/tasks/transfers/client.py">get_status</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This method retrieves the current status for each video from a specified integration and index. It returns an object containing lists of videos grouped by status. See the [Task object](/v1.3/api-reference/tasks/the-task-object) page for details on each status.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.tasks.transfers.get_status(
    integration_id="6298d673f1090f1100476d4c",
    index_id="6298d673f1090f1100476d4c",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**integration_id:** `str` ‚Äî The unique identifier of the integration for which you want to retrieve the status of your imported videos. You can retrieve it from the [Integrations](https://playground.twelvelabs.io/dashboard/integrations) page.
    
</dd>
</dl>

<dl>
<dd>

**index_id:** `str` ‚Äî The unique identifier of the index for which you want to retrieve the status of your imported videos.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.tasks.transfers.<a href="src/twelvelabs/tasks/transfers/client.py">get_logs</a>(...)</code></summary>
<dl>
<dd>

#### üìù Description

<dl>
<dd>

<dl>
<dd>

This endpoint returns a chronological list of import operations for the specified integration. The list is sorted by creation date, with the oldest imports first. Each item in the list contains:
- The number of videos in each status
- Detailed error information for failed uploads, including filenames and error messages.

Use this endpoint to track import progress and troubleshoot potential issues across multiple operations.
</dd>
</dl>
</dd>
</dl>

#### üîå Usage

<dl>
<dd>

<dl>
<dd>

```python
from twelvelabs import TwelveLabs

client = TwelveLabs(
    api_key="YOUR_API_KEY",
)
client.tasks.transfers.get_logs(
    integration_id="6298d673f1090f1100476d4c",
)

```
</dd>
</dl>
</dd>
</dl>

#### ‚öôÔ∏è Parameters

<dl>
<dd>

<dl>
<dd>

**integration_id:** `str` ‚Äî The unique identifier of the integration for which you want to retrieve the import logs. You can retrieve it from the [Integrations](https://playground.twelvelabs.io/dashboard/integrations) page.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` ‚Äî Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

