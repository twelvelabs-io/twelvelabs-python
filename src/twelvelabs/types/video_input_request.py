# This file was auto-generated by Fern from our API Definition.

import typing

import pydantic
from ..core.pydantic_utilities import IS_PYDANTIC_V2, UniversalBaseModel
from .media_source import MediaSource
from .video_input_request_embedding_option_item import VideoInputRequestEmbeddingOptionItem
from .video_input_request_embedding_scope_item import VideoInputRequestEmbeddingScopeItem
from .video_segmentation import VideoSegmentation


class VideoInputRequest(UniversalBaseModel):
    """
    Required if the `input_type` parameter is `video`.
    """

    media_source: MediaSource
    start_sec: typing.Optional[float] = pydantic.Field(default=None)
    """
    The start time in seconds for processing the video file.
    
    Use this parameter to process a portion of the video file starting from a specific time.
    
    **Default**: 0 (start from the beginning)
    """

    end_sec: typing.Optional[float] = pydantic.Field(default=None)
    """
    The end time in seconds for processing the video file.
    
    Use this parameter to process a portion of the video file ending at a specific time. The end time must be greater than the start time.
    **Default**: End of the video file
    """

    segmentation: typing.Optional[VideoSegmentation] = None
    embedding_option: typing.Optional[typing.List[VideoInputRequestEmbeddingOptionItem]] = pydantic.Field(default=None)
    """
    The types of embeddings to generate for the video.
    
    **Values:**
    - `visual`: Generates embeddings based on visual content (scenes, objects, actions)
    - `audio`: Generates embeddings based on audio content (sounds, music, effects)
    - `transcription`: Generates embeddings based on transcribed speech
    
    You can specify multiple options to generate different types of embeddings for the same video.
    
    **Default**: `["visual", "audio", "transcription"]`
    """

    embedding_scope: typing.Optional[typing.List[VideoInputRequestEmbeddingScopeItem]] = pydantic.Field(default=None)
    """
    The scope for which you wish to generate embeddings.
    
    **Values**:
    - `clip`: Generates one embedding for each segment
    - `asset`: Generates one embedding for the entire video file. Use this scope for videos up to 10-30 seconds to maintain optimal performance.
    
    You can specify multiple scopes to generate embeddings at different levels.
    
    **Default**: `["clip", "asset"]`
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
